# -*- coding: utf-8 -*-
'''
@Project ï¼šresnet.py 
@File    ï¼šdata_augmentation.py
@Author  ï¼šJackwxiao
@Date    ï¼š2022/4/2 15:05 
'''

import torch
import torchvision
from torch import nn
from d2l import torch as d2l

# d2l.set_figsize()
# img = d2l.Image.open('../img/cat1.jpg')
# d2l.plt.imshow(img)
#
# #æ­¤å‡½æ•°åœ¨è¾“å…¥å›¾åƒimgä¸Šå¤šæ¬¡è¿è¡Œå›¾åƒå¢å¹¿æ–¹æ³•augå¹¶æ˜¾ç¤ºæ‰€æœ‰ç»“æœã€‚
# def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
#     Y = [aug(img) for _ in range(num_rows * num_cols)]
#     d2l.show_images(Y, num_rows, num_cols, scale=scale)
# # å·¦å³ç¿»è½¬å›¾åƒ
# apply(img, torchvision.transforms.RandomHorizontalFlip())
# # ä¸Šä¸‹ç¿»è½¬å›¾åƒ
# apply(img, torchvision.transforms.RandomVerticalFlip())
# # éšæœºè£å‰ª ä¸€ä¸ªé¢ç§¯ä¸ºåŸå§‹é¢ç§¯10%åˆ°100%çš„åŒºåŸŸï¼Œè¯¥åŒºåŸŸçš„å®½é«˜æ¯”ä»0.5åˆ°2ä¹‹é—´éšæœºå–å€¼,ç„¶åï¼ŒåŒºåŸŸçš„å®½åº¦å’Œé«˜åº¦éƒ½è¢«ç¼©æ”¾åˆ°200åƒç´ ,ğ‘ å’Œ ğ‘ ä¹‹é—´çš„éšæœºæ•°æŒ‡çš„æ˜¯åœ¨åŒºé—´ [ğ‘,ğ‘] ä¸­é€šè¿‡å‡åŒ€é‡‡æ ·è·å¾—çš„è¿ç»­å€¼ã€‚
# shape_aug = torchvision.transforms.RandomResizedCrop(
#     (200, 200), scale=(0.1, 1), ratio=(0.5, 2))
# apply(img, shape_aug)
#
# # æ”¹å˜é¢œè‰²ã€‚ æˆ‘ä»¬å¯ä»¥æ”¹å˜å›¾åƒé¢œè‰²çš„å››ä¸ªæ–¹é¢ï¼šäº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œè‰²è°ƒ, åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬[éšæœºæ›´æ”¹å›¾åƒçš„äº®åº¦]ï¼Œéšæœºå€¼ä¸ºåŸå§‹å›¾åƒçš„50%ï¼ˆ 1âˆ’0.5 ï¼‰åˆ°150%ï¼ˆ 1+0.5 ï¼‰ä¹‹é—´ã€‚
# apply(img, torchvision.transforms.ColorJitter(
#     brightness=0.5, contrast=0, saturation=0, hue=0))
#
# # éšæœºæ›´æ”¹å›¾åƒçš„è‰²è°ƒ
# apply(img, torchvision.transforms.ColorJitter(
#     brightness=0, contrast=0, saturation=0, hue=0.5))
#
# # éšæœºæ›´æ”¹å›¾åƒçš„äº®åº¦ï¼ˆbrightnessï¼‰ã€å¯¹æ¯”åº¦ï¼ˆcontrastï¼‰ã€é¥±å’Œåº¦ï¼ˆsaturationï¼‰å’Œè‰²è°ƒï¼ˆhueï¼‰
# color_aug = torchvision.transforms.ColorJitter(
#     brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)
# apply(img, color_aug)
#
# # åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å°†ç»“åˆå¤šç§å›¾åƒå¢å¹¿æ–¹æ³•ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸€ä¸ªComposeå®ä¾‹æ¥ç»¼åˆä¸Šé¢å®šä¹‰çš„ä¸åŒçš„å›¾åƒå¢å¹¿æ–¹æ³•ï¼Œå¹¶å°†å®ƒä»¬åº”ç”¨åˆ°æ¯ä¸ªå›¾åƒã€‚
# augs = torchvision.transforms.Compose([
#     torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])
# apply(img, augs)

print("++++++++++++++++++++++++++++++++++++++++++++++++++")

# ä½¿ç”¨å›¾åƒå¢å¹¿è¿›è¡Œè®­ç»ƒ
all_images = torchvision.datasets.CIFAR10(train=True, root="../data",
                                          download=True)
d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8)

# åªä½¿ç”¨æœ€ç®€å•çš„éšæœºå·¦å³ç¿»è½¬
train_augs = torchvision.transforms.Compose([
     torchvision.transforms.RandomHorizontalFlip(),
     torchvision.transforms.ToTensor()])

test_augs = torchvision.transforms.Compose([
     torchvision.transforms.ToTensor()])

# å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œä»¥ä¾¿äºè¯»å–å›¾åƒå’Œåº”ç”¨å›¾åƒå¢å¹¿
def load_cifar10(is_train, augs, batch_size):
    dataset = torchvision.datasets.CIFAR10(root="../data", train=is_train,
                                           transform=augs, download=True)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())
    return dataloader

# ä½¿ç”¨å¤šGPUå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°
#@save
def train_batch_ch13(net, X, y, loss, trainer, devices):
    """ç”¨å¤šGPUè¿›è¡Œå°æ‰¹é‡è®­ç»ƒ"""
    if isinstance(X, list):
        # å¾®è°ƒBERTä¸­æ‰€éœ€ï¼ˆç¨åè®¨è®ºï¼‰
        X = [x.to(devices[0]) for x in X]
    else:
        X = X.to(devices[0])
    y = y.to(devices[0])
    net.train()
    trainer.zero_grad()
    pred = net(X)
    l = loss(pred, y)
    l.sum().backward()
    trainer.step()
    train_loss_sum = l.sum()
    train_acc_sum = d2l.accuracy(pred, y)
    return train_loss_sum, train_acc_sum

#@save
def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,
               devices=d2l.try_all_gpus()):
    """ç”¨å¤šGPUè¿›è¡Œæ¨¡å‹è®­ç»ƒ"""
    timer, num_batches = d2l.Timer(), len(train_iter)
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],
                            legend=['train loss', 'train acc', 'test acc'])
    net = nn.DataParallel(net, device_ids=devices).to(devices[0])
    for epoch in range(num_epochs):
        # 4ä¸ªç»´åº¦ï¼šå‚¨å­˜è®­ç»ƒæŸå¤±ï¼Œè®­ç»ƒå‡†ç¡®åº¦ï¼Œå®ä¾‹æ•°ï¼Œç‰¹ç‚¹æ•°
        metric = d2l.Accumulator(4)
        for i, (features, labels) in enumerate(train_iter):
            timer.start()
            l, acc = train_batch_ch13(
                net, features, labels, loss, trainer, devices)
            metric.add(l, acc, labels.shape[0], labels.numel())
            timer.stop()
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (metric[0] / metric[2], metric[1] / metric[3],
                              None))
        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {metric[0] / metric[2]:.3f}, train acc '
          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '
          f'{str(devices)}')


# å®šä¹‰train_with_data_augå‡½æ•°ï¼Œä½¿ç”¨å›¾åƒå¢å¹¿æ¥è®­ç»ƒæ¨¡å‹.è¯¥å‡½æ•°è·å–æ‰€æœ‰çš„GPUï¼Œå¹¶ä½¿ç”¨Adamä½œä¸ºè®­ç»ƒçš„ä¼˜åŒ–ç®—æ³•ï¼Œå°†å›¾åƒå¢å¹¿åº”ç”¨äºè®­ç»ƒé›†ï¼Œæœ€åè°ƒç”¨åˆšåˆšå®šä¹‰çš„ç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹çš„train_ch13å‡½æ•°ã€‚
batch_size, devices, net = 256, d2l.try_all_gpus(), d2l.resnet18(10, 3)

def init_weights(m):
    if type(m) in [nn.Linear, nn.Conv2d]:
        nn.init.xavier_uniform_(m.weight)

net.apply(init_weights)

def train_with_data_aug(train_augs, test_augs, net, lr=0.001):
    train_iter = load_cifar10(True, train_augs, batch_size)
    test_iter = load_cifar10(False, test_augs, batch_size)
    loss = nn.CrossEntropyLoss(reduction="none")
    trainer = torch.optim.Adam(net.parameters(), lr=lr)
    train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices)

train_with_data_aug(train_augs, test_augs, net)